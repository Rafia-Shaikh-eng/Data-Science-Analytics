{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rafia-Shaikh-eng/Data-Science-Analytics/blob/main/1_csv_exercise_solution_ETL_Extract.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "liGJk2bhqEns"
      },
      "source": [
        "# Goal of the ETL Lesson\n",
        "\n",
        "One goal of this ETL pipelines lesson is to take the [World Bank Project data set](https://datacatalog.worldbank.org/dataset/world-bank-projects-operations) and merge this data with the [World Bank indicator data](https://data.worldbank.org/indicator/SP.POP.TOTL). Then you'll load the merged data into a database.\n",
        "\n",
        "In the process, you'll need to transform these data sets in different ways. And finally, you'll write a single Python module that reads in these date sets, transforms them, and loads the results into the database all in one step.\n",
        "\n",
        "# Extracting data from a csv file\n",
        "\n",
        "The first step in an ETL pipeline is extraction. Data comes in all types of different formats, and you'll practice extracting data from csv files, json files, xml files, SQL databases, and the web.\n",
        "\n",
        "In this first exercise, you'll practice extracting data from a CSV file and then navigating through the results. You'll see that extracting data is not always a straight-forward process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BhTfiQxqEnx"
      },
      "source": [
        "# Part 1 projects_data.csv\n",
        "\n",
        "There are two csv files loaded into this workspace:\n",
        "* projects_data.csv\n",
        "* population_data.csv\n",
        "\n",
        "As a first step, try importing the projects data using the pandas [read_csv method](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html). The file path is just 'projects_data.csv'. You can see the file if you click on File->Open in the workspace."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O7zBdKB0qEnx"
      },
      "outputs": [],
      "source": [
        "## TODO: import the projects_data.csv file using the pandas library\n",
        "import pandas as pd\n",
        "df_projects = pd.read_csv('projects_data.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vk2zUFRPqEnz"
      },
      "source": [
        "Did you get a DType warning? Read about what this warning is in the [pandas documentation](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.errors.DtypeWarning.html).\n",
        "\n",
        "Pandas could not automatically figure out the data type for each column (ie integer, string, etc.). That is because some columns have multiple data types. In other words, this data is somewhat messy.\n",
        "\n",
        "Try reading in the data set again using the read_csv() method. This time, also use the option dtype=str so that pandas treats everything like a string."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IrVP2tTfqEn0"
      },
      "outputs": [],
      "source": [
        "# TODO: Read in the projects_data.csv file using the read_csv method\n",
        "# and dtype = str option\n",
        "df_projects = pd.read_csv('projects_data.csv', dtype=str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fEKkTcUUqEn0"
      },
      "outputs": [],
      "source": [
        "# TODO: Run the cell below to see what the data looks like\n",
        "df_projects.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l-6q5dj-qEn0"
      },
      "outputs": [],
      "source": [
        "# TODO: count the number of null values in the data set\n",
        "# use the isnull() and sum() methods\n",
        "df_projects.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hp6moDijqEn1"
      },
      "source": [
        "Notice that the number 18248 shows up multiple times. There is also a countryname column with 0 missing values and a Country column with 14045 missing values. This data set has some issues that will need to be solved in the transform part of the pipeline.\n",
        "\n",
        "Next, output the size of the data frame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gxhoyg4eqEn1"
      },
      "outputs": [],
      "source": [
        "# TODO: output the shape of the data frame\n",
        "df_projects.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ha9RI85UqEn2"
      },
      "source": [
        "The number 18248 is interesting. Many columns in the data set are filled with only NaN values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpRfkl_CqEn2"
      },
      "source": [
        "# Part 2 population_data.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxu6ogQoqEn2"
      },
      "source": [
        "Next, use the pandas read_csv method to read in the population_data.csv file. The path to this file is \"population_data.csv\". You'll see that the results are not as expected."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lFiUI95JqEn3"
      },
      "outputs": [],
      "source": [
        "# TODO: read in the population_data.csv file\n",
        "df_population = pd.read_csv('population_data.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MuySScZqEn3"
      },
      "source": [
        "There is something wrong with this data set. You should see an error should say \"expected 3 fields in line 5, saw 63\". What might have happened? Try printing out the first few lines of the data file to see what the issue might be."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FfchTOa2qEn3"
      },
      "outputs": [],
      "source": [
        "# TODO: Print out the first 10 lines of the data set, line by line.\n",
        "# HINT: You can't use the read_csv method from pandas\n",
        "# HINT: to do this manually, you'll need to use pure Python\n",
        "# HINT: the open(), readline(), and close() methods should be helpful\n",
        "# HINT: Use a for loop\n",
        "f = open('population_data.csv')\n",
        "for i in range(10):\n",
        "    line = f.readline()\n",
        "    print('line: ', i,  line)\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mTLcpOWqEn4"
      },
      "source": [
        "The first four lines in the file are not properly formatted and don't contain data. Next, read in the data using the read_csv method. But this time, use the skiprows option."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHA9Ow3kqEn4"
      },
      "outputs": [],
      "source": [
        "# TODO: read in population data skipping the first four rows\n",
        "df_population = pd.read_csv('population_data.csv', skiprows=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "funQzVVmqEn4"
      },
      "outputs": [],
      "source": [
        "# TODO: Run this cell to see what the data looks like\n",
        "df_population.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNQM33hlqEn5"
      },
      "source": [
        "Make sure to scroll over to see what the last column looks like. That last column, called 'Unnamed: 62', doesn't look very useful and is filled with NaN values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jOu-LJwtqEn5"
      },
      "outputs": [],
      "source": [
        "# TODO: Count the number of null values in each column\n",
        "df_population.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBZ0sSuiqEn5"
      },
      "source": [
        "It looks like every year column has at least one NaN value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zidbtiqnqEn5"
      },
      "outputs": [],
      "source": [
        "# TODO: Sum the null values by column\n",
        "# HINT: In the sum method, use axis=1\n",
        "df_population.isnull().sum(axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36oma0W5qEn6"
      },
      "source": [
        "And it looks like almost every row has only one null value. That is probably from the 'Unnamed: 62' column that doesn't have any relevant information in it. Next, drop the 'Unnamed: 62' column from the data frame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h6EfvvfsqEn6"
      },
      "outputs": [],
      "source": [
        "# TODO: drop the 'Unnamed: 62' column from the data frame,\n",
        "# and save the results in the df_population variable\n",
        "\n",
        "df_population = df_population.drop('Unnamed: 62', axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sqacy844qEn6"
      },
      "outputs": [],
      "source": [
        "# TODO: Now output any row that contains a null value.\n",
        "# HINT: Use the isnull() and any() methods. You'll want to use axis=1\n",
        "# in the any method.\n",
        "df_population[df_population.isnull().any(axis=1)]"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}